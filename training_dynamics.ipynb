{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "import numpy as np\n",
    "import imageio\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    \"animation.writer\": \"ffmpeg\",\n",
    "    \"font.family\": \"serif\",  # use serif/main font for text elements\n",
    "    \"font.size\": 12,\n",
    "    \"text.usetex\": True,     # use inline math for ticks\n",
    "    \"pgf.rcfonts\": False,    # don't setup fonts from rc parameters\n",
    "    \"hist.bins\": 20, # default number of bins in histograms\n",
    "    \"pgf.preamble\": [\n",
    "         \"\\\\usepackage{units}\",          # load additional packages\n",
    "         \"\\\\usepackage{metalogo}\",\n",
    "         \"\\\\usepackage{unicode-math}\",   # unicode math setup\n",
    "         r\"\\setmathfont{xits-math.otf}\",\n",
    "         r\"\\setmainfont{DejaVu Serif}\",  # serif font via preamble\n",
    "         r'\\usepackage{color}',\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Data\n",
    "## orthogonal toy example\n",
    "x = torch.Tensor(np.array([-0.5,2]).reshape(-1,1)) \n",
    "y = torch.Tensor(np.array([-1,1]).reshape(-1,1)) \n",
    "## non-orthognal toy example\n",
    "#x = torch.Tensor(np.array([-1.5,-1.,0,0.25,2]).reshape(-1,1))\n",
    "#y = torch.Tensor(np.array([0.7,-0.3,-0.3,0.4,0.2]).reshape(-1,1)) \n",
    "\n",
    "# torch can only train on Variable, so convert them to Variable\n",
    "x, y = Variable(x), Variable(y)\n",
    "\n",
    "# view data\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.scatter(x.data.numpy(), y.data.numpy(), color = \"tab:green\")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Neural network architecture and initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    1 hidden layer Relu network architecture\n",
    "    \"\"\"\n",
    "    def __init__(self, n_feature, n_hidden, n_output, init_scale=1, bias_hidden=True, bias_output=False, balanced=True, **kwargs):\n",
    "        \"\"\"\n",
    "        n_feature: dimension of input\n",
    "        n_hidden: number of hidden neurons\n",
    "        n_output: dimension of output\n",
    "        init_scale: the weights are initialized ~ N(0, init_scale^2/(md)) where d is the input dimension of this layer (without bias) and m the width\n",
    "        bias_hidden: if True, use bias parameters in hidden layer. Use no bias otherwise\n",
    "        bias_output: if True, use bias parameters in output layer. Use no bias otherwise\n",
    "        balanced: if True, use a balanced initialisation\n",
    "        \"\"\"\n",
    "        super(Net, self).__init__()\n",
    "        self.init_scale = init_scale\n",
    "        \n",
    "        self.hidden = torch.nn.Linear(n_feature, n_hidden, bias=bias_hidden)   # hidden layer with rescaled init\n",
    "        torch.nn.init.normal_(self.hidden.weight.data, std=(init_scale/np.sqrt(n_hidden*n_feature)))\n",
    "        if bias_hidden:\n",
    "            torch.nn.init.normal_(self.hidden.bias.data, std=(init_scale/np.sqrt(n_hidden*n_feature)))\n",
    "            \n",
    "        self.predict = torch.nn.Linear(n_hidden, n_output, bias=bias_output)   # output layer with rescaled init\n",
    "        if balanced: # balanced initialisation\n",
    "            if bias_hidden:\n",
    "                neuron_norms = (self.hidden.weight.data.norm(dim=1).square()+self.hidden.bias.data.square()).sqrt()\n",
    "            else:\n",
    "                neuron_norms = (self.hidden.weight.data.norm(dim=1).square()).sqrt()\n",
    "            self.predict.weight.data = 2*torch.bernoulli(0.5*torch.ones_like(self.predict.weight.data)) -1\n",
    "            self.predict.weight.data *= neuron_norms\n",
    "        else:\n",
    "            torch.nn.init.normal_(self.predict.weight.data, std=(init_scale/np.sqrt(n_hidden)))\n",
    "        if bias_output:\n",
    "            torch.nn.init_normal_(self.predict.bias.data, std=(init_scale/np.sqrt(n_hidden)))\n",
    "            \n",
    "        self.activation = kwargs.get('activation', torch.nn.ReLU()) # activation of hidden layer\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = self.activation(self.hidden(z))     \n",
    "        z = self.predict(z)             # linear output\n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Visualisation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multicolor_label(ax,list_of_strings,list_of_colors,axis='x',anchorpad=0,**kw):\n",
    "    \"\"\"this function creates axes labels with multiple colors\n",
    "    ax: specifies the axes object where the labels should be drawn\n",
    "    list_of_strings: a list of all of the text items\n",
    "    list_if_colors: a corresponding list of colors for the strings\n",
    "    axis:'x', 'y', or 'both' and specifies which label(s) should be drawn\"\"\"\n",
    "    from matplotlib.offsetbox import AnchoredOffsetbox, TextArea, HPacker, VPacker\n",
    "\n",
    "    # x-axis label\n",
    "    if axis=='x' or axis=='both':\n",
    "        boxes = [TextArea(text, textprops=dict(color=color, ha='left',va='bottom',**kw)) \n",
    "                    for text,color in zip(list_of_strings,list_of_colors) ]\n",
    "        xbox = HPacker(children=boxes,align=\"center\",pad=0, sep=60)\n",
    "        anchored_xbox = AnchoredOffsetbox(loc=3, child=xbox, pad=anchorpad,frameon=False,bbox_to_anchor=(0.27, -0.18),\n",
    "                                          bbox_transform=ax.transAxes, borderpad=0.)\n",
    "        ax.add_artist(anchored_xbox)\n",
    "\n",
    "    # y-axis label\n",
    "    if axis=='y' or axis=='both':\n",
    "        boxes = [TextArea(text, textprops=dict(color=color, ha='left',va='bottom',rotation=90,**kw)) \n",
    "                     for text,color in zip(list_of_strings[::-1],list_of_colors) ]\n",
    "        ybox = VPacker(children=boxes,align=\"center\", pad=0, sep=5)\n",
    "        anchored_ybox = AnchoredOffsetbox(loc=3, child=ybox, pad=anchorpad, frameon=False, bbox_to_anchor=(-0.10, 0.2), \n",
    "                                          bbox_transform=ax.transAxes, borderpad=0.)\n",
    "        ax.add_artist(anchored_ybox)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_single_frame(fig, arts, frame_number):\n",
    "    \"\"\"save as a pdf a single frame of an animation\n",
    "    fig: the figure to save\n",
    "    arts: list of images resulting in the animation\n",
    "    frame_number: the specific frame to save as a pdf\n",
    "    \"\"\"\n",
    "    # make sure everything is hidden\n",
    "    for frame_arts in arts:\n",
    "        for art in frame_arts:\n",
    "            art.set_visible(False)\n",
    "    # make the one artist we want visible\n",
    "    for i in range(len(arts[frame_number])):\n",
    "        arts[frame_number][i].set_visible(True)\n",
    "    fig.savefig(\"frame_{}.pdf\".format(frame_number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Neuron alignment visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init network\n",
    "net = Net(n_feature=1, n_hidden=60, n_output=1, init_scale=1e-6, balanced=True)     # define the network\n",
    " \n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001) # Gradient descent\n",
    "loss_func = torch.nn.MSELoss(reduction='mean')  # mean squared error\n",
    "\n",
    "n_samples = x.shape[0]\n",
    "n_iterations = 20000 # number of descent steps\n",
    "\n",
    "loss = torch.Tensor(np.array([0]))\n",
    "previous_loss = torch.Tensor(np.array([np.infty]))\n",
    "\n",
    "# plot parameters\n",
    "iter_geom = 1.05 #saved frames correspond to steps t=\\lceil k^{iter_geom} \\rceil for all integers k \n",
    "last_iter = 0\n",
    "frame = 0\n",
    "ims = []\n",
    "fig = plt.figure(\"Training dynamics\")\n",
    "plt.ioff()\n",
    "\n",
    "# Cosmetics\n",
    "c1 = 'tab:green' # color of left axis\n",
    "c2 = 'tab:blue' # color of right axis\n",
    "\n",
    "plt.subplots_adjust(left=0.15, right=0.85)\n",
    "\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.set_xlim(x.min()-1,x.max()+1)\n",
    "ax1.set_ylim(y.min()-2.6,y.max()+1)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.axhline(0, linestyle='--', alpha=0.5)\n",
    "ax1.set_ylabel(r'$h_{\\theta}(x)$', fontsize=20)\n",
    "ax2.set_ylabel(r'$\\mathsf{s}_j\\|w_j\\|$', fontsize=20)\n",
    "\n",
    "ax1.yaxis.label.set_color(c1)\n",
    "ax2.yaxis.label.set_color(c2)\n",
    "\n",
    "ax2.spines[\"left\"].set_edgecolor(c1)\n",
    "ax2.spines[\"right\"].set_edgecolor(c2)\n",
    "\n",
    "ax1.tick_params(axis='y', colors=c1)\n",
    "ax2.tick_params(axis='y', colors=c2)\n",
    "multicolor_label(ax1,(r'$x$',r'$-w_{j,2}/w_{j,1}$'),(c1,c2),axis='x', fontsize=20)\n",
    "#######\n",
    "\n",
    "losses = []\n",
    "z = torch.Tensor(np.linspace(x.min()-1,x.max()+1,100).reshape(-1,1))\n",
    "\n",
    "# train the network\n",
    "for it in tqdm(range(n_iterations)):\n",
    "    previous_loss = loss\n",
    "    prediction = net(x)\n",
    "    loss = loss_func(prediction, y) # training loss\n",
    "\n",
    "    if (it<2 or it==int(last_iter*iter_geom)+1): # save frame in animation\n",
    "        im1, = ax1.plot(z.data.numpy(), net(z).data.numpy(), '-', c=c1, lw=2, animated=True) # current estimated function\n",
    "        # showing each neuron individually\n",
    "        im2 = ax2.scatter(-(net.hidden.bias.data.reshape(-1)/net.hidden.weight.data.reshape(-1)).numpy(), net.predict.weight.data.reshape(-1).numpy(), animated=True, c=c2, marker='*')\n",
    "        t = ax1.annotate(\"iteration: \"+str(it)+\", frame: \"+str(frame),(0.4,0.95),xycoords='figure fraction',annotation_clip=False) # add text\n",
    "        if it == 0:\n",
    "            ax1.scatter(x.data.numpy(), y.data.numpy(), color=c1)\n",
    "        ims.append([im1,im2,t])\n",
    "        last_iter = it\n",
    "        frame += 1\n",
    "\n",
    "    losses.append(loss.data.numpy())\n",
    "    optimizer.zero_grad()   # clear gradients for next train\n",
    "    loss.backward()         # backpropagation, compute gradients\n",
    "    optimizer.step()        # gradient descent step\n",
    "    \n",
    "ani = animation.ArtistAnimation(fig, ims, interval=100, repeat=False)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani.save('alignment.mp4', fps=10, dpi=120) # save animation as .mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save specific frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_single_frame(fig, ims, 147) # save specific frame of animation as a .pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loss profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses, lw=3)\n",
    "plt.ylim(ymin=0)\n",
    "#plt.xlim(xmin=0, xmax=20000)\n",
    "plt.ylabel(r'$L(\\theta)$',fontsize=20)\n",
    "plt.xlabel('Iterations', fontsize=20)\n",
    "plt.grid(alpha=0.2)\n",
    "plt.tight_layout()\n",
    "plt.savefig('loss_profile.pdf',fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
